{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader():\n",
    "    \n",
    "    def __init__(self, conf):\n",
    "        \n",
    "        self.batch_size = conf['batch_size']\n",
    "        self.in_memory = conf['in_memory']\n",
    "        self.channel = conf['channel']\n",
    "        \n",
    "        if self.in_memory:\n",
    "            self.width = conf['width']\n",
    "            self.height = conf['height']\n",
    "            self.image_arr = tf.placeholder(shape = [None, self.height, self.width, self.channel], dtype = tf.uint8)\n",
    "        \n",
    "        if not self.in_memory:\n",
    "            self.image_arr  = conf['data_path']\n",
    "            \n",
    "    def build_loader(self):\n",
    "\n",
    "        self.tr_dataset = tf.data.Dataset.from_tensor_slices(self.image_arr)\n",
    "\n",
    "        if not self.in_memory :\n",
    "            self.tr_dataset = self.tr_dataset.map(self._parse, num_parallel_calls = 4).prefetch(32)\n",
    "\n",
    "        self.tr_dataset = self.tr_dataset.shuffle(32)\n",
    "        self.tr_dataset = self.tr_dataset.repeat()\n",
    "        self.tr_dataset = self.tr_dataset.batch(self.batch_size)\n",
    "        iterator = tf.data.Iterator.from_structure(self.tr_dataset.output_types, self.tr_dataset.output_shapes)\n",
    "        self.next_batch = iterator.get_next()\n",
    "        self.init_op = iterator.make_initializer(self.tr_dataset)\n",
    "\n",
    "            \n",
    "    def _parse(self, image):\n",
    "        \n",
    "        image = tf.read_file(image)\n",
    "        image = tf.image.decode_png(image, channels = self.channel)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    def str2bool(v):\n",
    "        return v.lower() in ('true')\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--batch_size\", type = int, default = 4)\n",
    "    parser.add_argument(\"--in_memory\", type = str2bool, default = False)\n",
    "    parser.add_argument(\"--channel\", type = int, default = 3)\n",
    "    parser.add_argument(\"--width\", type = int, default = 64)\n",
    "    parser.add_argument(\"--height\", type = int, default = 64)\n",
    "    parser.add_argument(\"--data_direc\", type = str, default = './test_data/')\n",
    "    parser.add_argument(\"--result_path\", type = str, default = './result')\n",
    "    parser.add_argument(\"--test_num\", type = int, default = 3)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    conf = {}\n",
    "    \n",
    "    conf['batch_size'] = args.batch_size\n",
    "    conf['in_memory'] = args.in_memory\n",
    "    conf['channel'] = args.channel\n",
    "    conf['width'] = args.width\n",
    "    conf['height'] = args.height\n",
    "    conf['data_direc'] = args.data_direc\n",
    "    conf['result_path'] = args.result_path\n",
    "    conf['test_num'] = args.test_num\n",
    "    \n",
    "    img_list = sorted(os.listdir(conf['data_direc']))\n",
    "    conf['data_path'] = np.array([os.path.join(conf['data_direc'], ele) for ele in img_list])\n",
    "    \n",
    "    if not os.path.exists(conf['result_path']):\n",
    "        os.makedirs(conf['result_path'])\n",
    "    \n",
    "    data_loader = data_loader(conf)\n",
    "    data_loader.build_loader()\n",
    "    \n",
    "    tf_output = data_loader.next_batch\n",
    "    tf_output = tf_output[:,:50,:50,:]\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config = config)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if conf['in_memory']:\n",
    "        img_list = []\n",
    "        for ele in conf['data_path']:\n",
    "            img_list.append(np.array(Image.open(ele)))\n",
    "        img_list = np.array(img_list)\n",
    "        \n",
    "        sess.run(data_loader.init_op, feed_dict = {data_loader.image_arr : img_list})\n",
    "    else:\n",
    "        sess.run(data_loader.init_op)\n",
    "        \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(conf['test_num']):\n",
    "        \n",
    "        output = sess.run(tf_output)\n",
    "        for ele in output:\n",
    "            img = Image.fromarray(ele)\n",
    "            img.save(os.path.join(conf['result_path'], '%02d_result.png'%count))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
